---
format:
  revealjs:
    theme: [default, custom.scss]
    auto-stretch: false
    auto-play-media: true
    slide-number: true
    code-line-numbers: false
    progress: false
    preload-iframes: true
revealjs-plugins:
  - pointer
format-links: [html]
---

## {data-menu-title="Forside" background-image="figures/MAT110-flyer.png" background-position="top" background-size="cover"}

## {data-menu-title="ChatGPT" .center background-color="#E0E0E0"}

:::{style="background-color: #fff; box-shadow: 10px 10px 10px rgba(0, 0, 0, 0.15); border: 1px solid #9E9E9E;"}
![](figures/chatgpt.png){fig-align="center"}
:::

## {data-menu-title="GPT-UiO" background-iframe="https://www.uio.no/tjenester/it/ki/gpt-uio/" background-interactive="true"}

## {data-menu-title="GPT-2" background-iframe="https://openai.com/index/gpt-2-1-5b-release/" background-interactive="true"}

## {data-menu-title="Demo GPT-2" background-color="#E0E0E0"}
<!-- Terminal -->

## {data-menu-title="Et enklere prediksjonsproblem"}

::::{.columns style="font-size: 0.8em;"}

:::{.column width="25%"}
:::

:::{.column width="30%"}
| **_x_** | **_y_** |
|:---:|:---:|
| 0.619 | 5.127 |
| 0.351 | 4.294 |
| 0.687 | 6.107 |
| 0.558 | 5.023 |
| 0.075 | 3.894 |
| 0.780 | 5.350 |
| 0.609 | 5.537 |
| 0.629 | 5.477 |
| 0.102 | 4.453 |
| 0.360 | 4.979 |
| 0.297 | 5.878 |
:::

:::{.column width="30%"}
| **_x_** | **_y_** |
|:---:|:---:|
| 0.741 | 5.239 |
| 0.515 | 4.723 |
| 0.658 | 4.828 |
| 0.355 | 5.079 |
| 0.182 | 5.041 |
| 0.444 | 4.819 |
| 0.051 | 3.598 |
| 0.662 | 4.830 |
| 0.505 | 5.401 |
| [1.000]{style="color: #D81B60"} | [?]{style="color: #D81B60"} | 
:::

::::


## {data-menu-title="Et enklere prediksjonsproblem" background-iframe="figures/linreg_data_only.html" background-interactive="true"}

<!-- :::{style="padding-left: 20%;"} -->
<!-- <iframe width="1600px" height="800px" src="figures/linreg_data_only.html"></iframe> -->
<!-- ::: -->

## {.center data-menu-title="Lineær modell"}

Vår modell: 

$$
%\small
\begin{align}
\hat{\color{DarkBlue}{y}} &= \color{Purple}{f}(\color{DarkOrange}{x}, \boldsymbol{\color{teal}{\theta}}) \\[1em]
 &= \color{teal}{\theta}_0
 + \color{teal}{\theta}_1 \color{DarkOrange}{x}
\end{align}
$$

:::{.fragment}
Eller på _**vektorform**:_

:::{style="padding-left: 35%;"}
$$
%\small
\begin{align}
\hat{\color{DarkBlue}{y}} &= 
\boldsymbol{\color{teal}{\theta}}^{\intercal} \cdot \boldsymbol{\color{DarkOrange}{x}} \\
&= 
  \begin{bmatrix}
    \color{teal}{\theta}_0 & \color{teal}{\theta}_1
  \end{bmatrix}
  \begin{bmatrix}
    \color{DarkOrange}{x}_0 \\ \color{DarkOrange}{x}_1
  \end{bmatrix} \\
&= \color{teal}{\theta}_0 \color{DarkOrange}{x}_0 + \color{teal}{\theta}_1 \color{DarkOrange}{x}_1 \qquad \color{grey}{(\mathrm{med}\; x_0=1}) \\[0.5em]
&= \color{teal}{\theta}_0 + \color{teal}{\theta}_1 \color{DarkOrange}{x}_1
\end{align}
$$
:::
:::


## {data-menu-title="Et enklere prediksjonsproblem" background-iframe="figures/linreg_sliders.html" background-interactive="true"}


## {data-menu-title="Tapsfunksjon"}

:::{style="padding-top: 50px;"}
:::

::::{.columns}
:::{.column width="80%"}

:::{.r-stack}

![](figures/lossfunction/image-1.png)

![](figures/lossfunction/image-2.png){.fragment fragment-index=1}

![](figures/lossfunction/image-3.png){.fragment fragment-index=2}

![](figures/lossfunction/image-4.png){.fragment fragment-index=3}

![](figures/lossfunction/image-5.png){.fragment fragment-index=4}

![](figures/lossfunction/image-6.png){.fragment fragment-index=5}

![](figures/lossfunction/image-7.png){.fragment fragment-index=6}

![](figures/lossfunction/image-8.png){.fragment fragment-index=7}

:::

:::

<!-- :::{.column width="20%"} -->

:::{.absolute top="10%" left="75%" .fragment fragment-index=7 .fade-in-then-out}
$$
\small
L = (y - \hat{y})^2
$$
:::

:::{.absolute top="20%" left="75%" .fragment fragment-index=8}
$$
\small
L = \frac{1}{N} \sum_i^N (y_i - \hat{y}_i)^2
$$
:::
<!-- ::: -->

::::


## {data-menu-title="Linreg med tapsfunksjon" background-iframe="figures/linreg_loss.html" background-interactive="true"}

## {.center data-menu-title="Tapsfunksjon"}

$$
L =  (\color{teal}{\theta}_0+ \color{teal}{\theta}_1 \color{DarkOrange}{x} - \color{DarkBlue}{y})^2
$$



## {data-menu-title="På fjellet" background-image="figures/mountain.jpg"}

## {.center data-menu-title="Partiellderiverte"}

::::{.columns}
:::{.column width="50%"}
$$
\frac{\mathrm{d}}{\mathrm{d}x}
$$

:::{style="padding-top: 50px;"}
:::

:::{.fragment}
![](figures/2d_plot_example.png){fig-align="center" width="70%"}
:::
:::

:::{.column width="50%"}
:::{.fragment}
$$
\frac{\partial}{\partial x} , \quad \frac{\partial}{\partial y}
$$

![](figures/3d_plot_example.png){fig-align="center"}
:::
:::
::::

## {.center data-menu-title="Gradient"}

$$
\nabla L = 
\begin{bmatrix}
\frac{\partial \color{Purple}{f}}{\partial \color{teal}{x}} \\[0.2em]
\frac{\partial \color{Purple}{f}}{\partial \color{teal}{y}}
\end{bmatrix}
$$

## {.center data-menu-title="Gradient"}

$$
- \nabla L = 
\begin{bmatrix}
- \frac{\partial \color{Purple}{f}}{\partial \color{teal}{x}} \\[0.2em]
- \frac{\partial \color{Purple}{f}}{\partial \color{teal}{y}}
\end{bmatrix}
$$

## {data-menu-title="Gradient 1"}

:::{.absolute top="10%" left="25%"}
$$
\begin{align}
\frac{\partial L}{\partial \color{teal}{\theta_0}}
&=  \frac{\partial}{\partial \color{teal}{\theta_0}} (\color{teal}{\theta}_0+ \color{teal}{\theta}_1 \color{DarkOrange}{x} - \color{DarkBlue}{y})^2 \\
&=
\end{align}
$$
:::

## {data-menu-title="Gradient 1"}

:::{.absolute top="10%" left="25%"}
$$
\begin{align}
\frac{\partial L}{\partial \color{teal}{\theta_0}}
&=  \frac{\partial}{\partial \color{teal}{\theta_0}} (\color{teal}{\theta}_0+ \color{teal}{\theta}_1 \color{DarkOrange}{x} - \color{DarkBlue}{y})^2 \\
&= 2(\color{teal}{\theta}_0+ \color{teal}{\theta}_1 \color{DarkOrange}{x} - \color{DarkBlue}{y}) \frac{\partial}{\partial \color{teal}{\theta_0}} 
\color{teal}{\theta_0}
\end{align}
$$
:::

## {data-menu-title="Gradient 1"}

:::{.absolute top="10%" left="25%"}
$$
\begin{align}
\frac{\partial L}{\partial \color{teal}{\theta_0}}
&=  \frac{\partial}{\partial \color{teal}{\theta_0}} (\color{teal}{\theta}_0+ \color{teal}{\theta}_1 \color{DarkOrange}{x} - \color{DarkBlue}{y})^2 \\
&= 2(\color{teal}{\theta}_0+ \color{teal}{\theta}_1 \color{DarkOrange}{x} - \color{DarkBlue}{y}) \frac{\partial}{\partial \color{teal}{\theta_0}} 
\color{teal}{\theta_0} \\
&= 2(\color{teal}{\theta}_0+ \color{teal}{\theta}_1 \color{DarkOrange}{x} - \color{DarkBlue}{y})
\end{align}
$$
:::


## {data-menu-title="Linreg med gradient" background-iframe="figures/linreg_gradient.html" background-interactive="true"}

## {data-menu-title="Høydekurver" background-image="figures/kart.png"}


<!-- ## Gradient descent --> 


## {.center data-menu-title="Nevralnett"}

![](figures/neuralnet.png){width="70%" fig-align="center"}

## {.center data-menu-title="Nevralnett aktivering"}

![](figures/neuralnet_activations.png){fig-align="center"}


## {data-menu-title="GPT parameterantall" background-image="figures/gpt-parameters.png"}

:::{.fragment .absolute left="15%" bottom="-50px" width="700px"}
![](figures/datacentre.jpg){fig-align="center"}
:::

## {.center data-menu-title="Nevralnett forts."}

La oss skrive et nevralnett som en funksjon sammensatt av hvert lag $k$, der $k = 1, 2, \dots, K$: 

:::{style="padding-top: 40px;"}
:::

$$
\hat{y} = 
\color{Purple}{f}_K(
\color{Purple}{f}_{K-1}(
\color{Purple}{f}_{K-2}(
\dots (
\color{Purple}{f}_1(\boldsymbol{\color{DarkOrange}{x}}, \boldsymbol{\color{teal}{\theta}}_1) \dots ))))
$$

:::{style="padding-top: 50px;"}
:::

Hvordan finne parameterene $\boldsymbol{\color{teal}{\theta}}$ som gir minst mulig feil $L$?

## {data-menu-title="Kjerneregelen" .center background-color="#EDE7F6"}

:::{style="padding-left: 25%; font-size: 2em; font-weight: 400;"}
Kjerneregelen
:::

## {.center data-menu-title="Kjerneregelen for nevralnett"}

:::{.absolute top="-20px" right="-20px" width="200px"}
![](figures/neuralnet.png)
:::

:::{.fragment .fade-in-then-semi-out}
$$
\small
\frac{\partial L}{\partial\boldsymbol{\color{teal}{\theta}}_{K-1}} 
= \frac{\partial L}{\partial\color{Purple}{f}_{K}}
\frac{\partial \color{Purple}{f}_K}{\partial\boldsymbol{\color{teal}{\theta}}_{K-1}}
$$
:::

:::{.fragment .fade-in-then-semi-out}
$$
\small
\frac{\partial L}{\partial\boldsymbol{\color{teal}{\theta}}_{K-2}} 
= \frac{\partial L}{\partial \color{Purple}{f}_{K}}
\frac{\partial \color{Purple}{f}_K}{\partial\color{Purple}{f}_{K-1}}
\frac{\partial \color{Purple}{f}_{K-1}}{\partial\boldsymbol{\color{teal}{\theta}}_{K-2}}
$$
:::

:::{.fragment .fade-in-then-semi-out}
$$
\small
\frac{\partial L}{\partial\boldsymbol{\color{teal}{\theta}}_{K-3}} 
= \frac{\partial L}{\partial\color{Purple}{f}_{K}}
\frac{\partial \color{Purple}{f}_K}{\partial\color{Purple}{f}_{K-1}}
\frac{\partial \color{Purple}{f}_{K-1}}{\partial\color{Purple}{f}_{K-2}}
\frac{\partial \color{Purple}{f}_{K-2}}{\partial\boldsymbol{\color{teal}{\theta}}_{K-3}}
$$
:::

:::{.fragment}
$$
\small
\frac{\partial L}{\partial\boldsymbol{\color{teal}{\theta}}_{i}} 
= \frac{\partial L}{\partial\color{Purple}{f}_{K}}
\frac{\partial \color{Purple}{f}_{K}}{\partial\color{Purple}{f}_{K-1}}
\frac{\partial \color{Purple}{f}_{K-1}}{\partial\color{Purple}{f}_{K-2}}
\dots
\frac{\partial \color{Purple}{f}_{i+2}}{\partial\color{Purple}{f}_{i+1}}
\frac{\partial \color{Purple}{f}_{i+1}}{\partial\boldsymbol{\color{teal}{\theta}}_{i}}
$$
:::


## {data-menu-title="Autodiff" background-iframe="https://en.wikipedia.org/wiki/Automatic_differentiation" background-interactive="true"}

## Språkmodeller {.center background-color="#F1F8E9"}


<!-- ## Data {background-iframe="https://commoncrawl.org/"} -->


## {.center data-menu-title="Ingen ord på en datamaskin"} 


:::{style="font-size: 0.8em;"}

Det finnes ingen ord i en datamaskin, kun representasjoner.

:::{.fragment}
Tekst:
```{.c}
Matematikk er kult :)
```
:::

:::{.fragment}
Binær:
```{.c}
01001101 01100001 01110100 01100101 01101101 01100001 01110100
01101001 01101011 01101011 00100000 01100101 01110010 00100000
01101011 01110101 01101100 01110100 00100000 00111010 00101001
```
:::

:::{.fragment}
Desimal (base 10):
```{.c}
77 97 116 101 109 97 116 105 107 107 32 101 114 32 107 117 108
116 32 58 41
```
:::

:::

## {data-menu-title="Tokenization" .center}


```{.c}
  Mathematics is cool because it (...)

  
```

## {data-menu-title="Tokenization" .center}

```{.c}
  Mat  hemat  ics   is  cool  because  it (...)
   ↓     ↓     ↓    ↓     ↓      ↓      ↓ 
19044  10024  873  318  3608    780    340
```


## {data-menu-title="Vokabular"}

{{< include vocab.qmd >}}


## {.center data-menu-title="The humble vector" background-color="#F9FBE7"}

![](figures/simplevec.png){width="50%" fig-align="center"}



## 1D

::::{.columns}
:::{.column width="50%"}

:::{style="padding-top: 120px;"}
:::

![](figures/vector-1d.png)
:::

:::{.column width="50%"}

:::{style="padding-top: 120px;"}
:::

$$
\small
\boldsymbol{A} = 
\begin{bmatrix}
a_1
\end{bmatrix},
\boldsymbol{B} = 
\begin{bmatrix}
b_1
\end{bmatrix}
$$

:::
::::

:::{style="padding-top: 120px;"}
:::

:::{.fragment}
$$
\small
||\boldsymbol{A}-\boldsymbol{B}|| = \sqrt{(a_1-b_1)^2}
$$
:::

:::{.absolute top="-40px" right="-80px" width="150px"}
![](figures/brain1.jpg){fig-align="right"}
:::

## 2D

::::{.columns}
:::{.column width="50%"}
![](figures/vector-2d.png)
:::

:::{.column width="50%"}

:::{style="padding-top: 120px;"}
:::

$$
\small
\boldsymbol{A} = 
\begin{bmatrix}
a_1 \\ a_2
\end{bmatrix},
\boldsymbol{B} = 
\begin{bmatrix}
b_1 \\ b_2
\end{bmatrix}
$$

:::
::::

$$
\small
||\boldsymbol{A}-\boldsymbol{B}|| = \sqrt{(a_1-b_1)^2 + (a_2-b_2)^2}
$$

:::{.absolute top="-40px" right="-80px" width="150px"}
![](figures/brain2.jpg){fig-align="right"}
:::

## 3D

::::{.columns}
:::{.column width="50%"}
![](figures/vector-3d.png)
:::

:::{.column width="50%"}

:::{style="padding-top: 120px;"}
:::

$$
\small
\boldsymbol{A} = 
\begin{bmatrix}
a_1 \\ a_2 \\ a_3
\end{bmatrix},
\boldsymbol{B} = 
\begin{bmatrix}
b_1 \\ b_2 \\ b_3
\end{bmatrix}
$$

:::
::::

$$
\small
||\boldsymbol{A}-\boldsymbol{B}|| = \sqrt{(a_1-b_1)^2 + (a_2-b_2)^2 + (a_3-b_3)^2}
$$

:::{.absolute top="-40px" right="-80px" width="150px"}
![](figures/brain3.jpg){fig-align="right"}
:::


## ND

:::{style="padding-top: 60px;"}
:::

::::{.columns}
:::{.column width="30%"}
![](figures/vector-nd.png)
:::

:::{.column width="50%"}
$$
\small
\boldsymbol{A} = 
\begin{bmatrix}
a_1 \\ a_2 \\ \vdots \\ a_N 
\end{bmatrix},
\boldsymbol{B} = 
\begin{bmatrix}
b_1 \\ b_2 \\ \vdots \\ b_N
\end{bmatrix}
$$

:::
::::

$$
\small
||\boldsymbol{A}-\boldsymbol{B}|| = \sqrt{(a_1-b_1)^2 + (a_2-b_2)^2 + \dots +  (a_N-b_N)^2}
$$

:::{.absolute top="-40px" right="-80px" width="150px"}
![](figures/brain4.jpg){fig-align="right"}
:::


## {.center data-menu-title="GPT embedding-dimensjoner"}

En moderne språkmodell plasserer ord i et [3072]{style="color: #E91E63"}-dimensjonalt vektorrom

:::{style="padding-top: 60px;"}
:::

I vårt eksempel (_GPT-2_) har vi et [768]{style="color: #FF5722"}-dimensjonalt rom.

## {data-menu-title="Demo" background-color="#FFF8E1"}

## {data-menu-title="word2vec"}

:::{.r-stack}

![](figures/word2vec/word2vec-1.png){width="70%"}

:::{.fragment fragment-index=1}
![](figures/word2vec/word2vec-2.png){width="70%"}
:::

:::{.fragment fragment-index=2}
![](figures/word2vec/word2vec-3.png){width="70%"}
:::

:::{.fragment fragment-index=3}
![](figures/word2vec/word2vec-4.png){width="70%"}
:::

:::

:::{.fragment fragment-index=3 .absolute top="0px" right="0px" width="350px"}
![](figures/roma.webp)
:::


## {background-image="figures/attention_is_all_you_need.png" background-position="top" background_size="cover"}

:::{.absolute bottom="0px" right="10%" width="30%" style="background-color: #fff; box-shadow: 10px 10px 10px rgba(0, 0, 0, 0.15); border: 1px solid;"}
![](figures/attention_block.png){fig-align="center"}
:::

## {.center data-menu-title="Attention"}

<!-- Hvonrdan reaterer vi ting? -->

Math is fun! I like it. What do I like?

<!-- 37372 318 1257 0 314 588 340 13, 1867 466 314 588 30 -->

## {.center data-menu-title="Attention matrix"}

:::{style="font-size: 0.5em;"}
| | **math** | **is** | **fun** | **!** | **I** | **like** | **it** | **.** | **What** | **do** | **I** | **like** | **?** |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | 
| **math** | 1.0000 | 0.0000 | 0.0000 | 0.0000 | 0.0000 | 0.0000 | 0.0000 | 0.0000 | 0.0000 | 0.0000 | 0.0000 | 0.0000 | 0.0000 |
| **is** | 0.9357 | 0.0643 | 0.0000 | 0.0000 | 0.0000 | 0.0000 | 0.0000 | 0.0000 | 0.0000 | 0.0000 | 0.0000 | 0.0000 | 0.0000 |
| **fun** | 0.7342 | 0.1296 | 0.1362 | 0.0000 | 0.0000 | 0.0000 | 0.0000 | 0.0000 | 0.0000 |0.0000 | 0.0000 | 0.0000 | 0.0000 |
| **!** | 0.4835 | 0.1179 | 0.2959 | 0.1026 | 0.0000 | 0.0000 | 0.0000 | 0.0000 | 0.0000 |0.0000 | 0.0000 | 0.0000 | 0.0000 |
| **I** | 0.4432 | 0.1021 | 0.1672 | 0.1356 | 0.1519 | 0.0000 | 0.0000 | 0.0000 | 0.0000 |0.0000 | 0.0000 | 0.0000 | 0.0000 |
| **like** | 0.2441 | 0.1537 | 0.1081 | 0.1142 | 0.2886 | 0.0913 | 0.0000 | 0.0000 | 0.0000 |0.0000 | 0.0000 | 0.0000 | 0.0000 |
| **it** | 0.2979 | 0.0914 | 0.1043 | 0.1174 | 0.1961 | 0.1213 | 0.0716 | 0.0000 | 0.0000 |0.0000 | 0.0000 | 0.0000 | 0.0000 |
| **.** | 0.3669 | 0.0437 | 0.1165 | 0.0980 | 0.1606 | 0.0950 | 0.1059 | 0.0135 | 0.0000 |0.0000 | 0.0000 | 0.0000 | 0.0000 |
| **What** | 0.2511 | 0.0683 | 0.0633 | 0.0673 | 0.1283 | 0.0808 | 0.0839 | 0.0260 | 0.2310 |0.0000 | 0.0000 | 0.0000 | 0.0000 |
| **do** | 0.2306 | 0.0418 | 0.0663 | 0.0451 | 0.1580 | 0.0780 | 0.0495 | 0.0178 | 0.2829 |0.0301 | 0.0000 | 0.0000 | 0.0000 | 
| **I** | 0.2039 | 0.0373 | 0.0810 | 0.0562 | 0.0692 | 0.0753 | 0.0563 | 0.0172 | 0.2758 |0.0483 | 0.0794 | 0.0000 | 0.0000 |
| **like** | 0.1179 | 0.0637 | 0.0511 | 0.0490 | 0.1354 | 0.0393 | 0.0579 | 0.0262 | 0.1517 |0.0812 | 0.1790 | 0.0476 | 0.0000 |
| **?** | 0.2196 | 0.0172 | 0.0695 | 0.0325 | 0.0525 | 0.0376 | 0.0268 | 0.0091 | 0.3793 |0.0179 | 0.0646 | 0.0487 | 0.0247 |
:::


## {data-menu-title="Sammenheng mellom ord"}

:::{style="padding-left: 20%;"}
<iframe width="800px" height="800px" src="figures/attention_plot.html"></iframe>
:::

## {data-menu-title="Fin" background-color="#E1F5FE"}


:::{style="background-color: #fff; box-shadow: 10px 10px 10px rgba(0, 0, 0, 0.15);"}
![](figures/chatgpt.png){fig-align="center"}
:::


:::{.absolute top="50%" left="30%" width="150px" height="200px" style="background-color: #fff; box-shadow: 10px 10px 10px rgba(0, 0, 0, 0.15); transform: rotate(-15deg);"}
![](figures/thomas_calculus.webp){fig-align="center"}
:::

:::{.absolute top="50%" left="55%" width="150px" height="200px" style="background-color: #fff; box-shadow: 10px 10px 10px rgba(0, 0, 0, 0.15); transform: rotate(15deg);"}
![](figures/edwards.webp){fig-align="center"}
:::


:::{.absolute top="55%" left="47%" style="font-size: 1.3em;"}
💕
:::


<!-- ## {data-menu-title="Blank" background-color="#FAFAFA"} -->

<!-- Hidden iframes, just to make sure quarto-render includes the files -->

<!-- ## Flow -->

<!-- - gpt demo -->
<!-- - word-for-word. how to compute the next one -->
<!-- - show script for next word probabilities -->
<!-- - transition: how to compute next value. start with an easier problem. -->
<!-- - linear regression (with a colored dot/line) -->
  <!-- - vector / matrix notation -->
<!-- - derivatives --> 
  <!-- - mountain + fog -->
  <!-- - partial derivatives -->
<!-- - fitness landscape v/ arrows -->
<!-- - neural networks -->
  <!-- - chain rule -->
  <!-- - for big models? -> autodiff -->
<!-- - transition: okay so we can model the future. how to do this for words? -->
<!-- - no words on a computer (maybe show binary). tokenisation -->
<!-- - words have meaning - how to implement this. word2vec -->
<!-- - vectors and vector spaces -->


<!-- ## MAT110 -->

<!-- - Parametertilpasning polynom -->
  <!-- - Derivasjon -->
  <!-- - Fitness landscape -->

<!-- - Vektorrom --> 
  <!-- - word2vec --> 
